{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30975f2e-ec2f-472e-8b73-b2abdd3cdd6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting labelme\n",
      "  Using cached labelme-5.1.1.tar.gz (1.5 MB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: tensorflow in c:\\users\\is-os\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (2.6.0)\n",
      "Collecting tensorflow-gpu\n",
      "  Using cached tensorflow_gpu-2.10.1-cp39-cp39-win_amd64.whl (455.9 MB)\n",
      "Collecting opencv-python\n",
      "  Using cached opencv_python-4.7.0.68-cp37-abi3-win_amd64.whl (38.2 MB)\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.6.2-cp39-cp39-win_amd64.whl (7.2 MB)\n",
      "     ---------------------------------------- 7.2/7.2 MB 1.3 MB/s eta 0:00:00\n",
      "Collecting albumentations\n",
      "  Using cached albumentations-1.3.0-py3-none-any.whl (123 kB)\n",
      "Collecting imgviz>=0.11\n",
      "  Using cached imgviz-1.6.2.tar.gz (7.7 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting natsort>=7.1.0\n",
      "  Using cached natsort-8.2.0-py3-none-any.whl (37 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\is-os\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from labelme) (1.23.5)\n",
      "Collecting Pillow>=2.8\n",
      "  Downloading Pillow-9.4.0-cp39-cp39-win_amd64.whl (2.5 MB)\n",
      "     ---------------------------------------- 2.5/2.5 MB 2.3 MB/s eta 0:00:00\n",
      "Collecting PyYAML\n",
      "  Downloading PyYAML-6.0-cp39-cp39-win_amd64.whl (151 kB)\n",
      "     -------------------------------------- 151.6/151.6 kB 2.2 MB/s eta 0:00:00\n",
      "Collecting qtpy!=1.11.2\n",
      "  Downloading QtPy-2.3.0-py3-none-any.whl (83 kB)\n",
      "     ---------------------------------------- 83.6/83.6 kB 4.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: termcolor in c:\\users\\is-os\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from labelme) (2.1.0)\n",
      "Collecting PyQt5!=5.15.3,!=5.15.4\n",
      "  Downloading PyQt5-5.15.7-cp37-abi3-win_amd64.whl (6.8 MB)\n",
      "     ---------------------------------------- 6.8/6.8 MB 2.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: colorama in c:\\users\\is-os\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from labelme) (0.4.6)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.37.0 in c:\\users\\is-os\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from tensorflow) (1.42.0)\n",
      "Collecting keras>=2.4.0\n",
      "  Using cached keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\is-os\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from tensorflow) (3.17.2)\n",
      "Requirement already satisfied: wheel>=0.35 in c:\\users\\is-os\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from tensorflow) (0.35.1)\n",
      "Collecting clang~=5.0\n",
      "  Downloading clang-5.0.tar.gz (30 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: gast==0.4.0 in c:\\users\\is-os\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: h5py>=3.1.0 in c:\\users\\is-os\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from tensorflow) (3.7.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in c:\\users\\is-os\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in c:\\users\\is-os\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: tensorboard~=2.6 in c:\\users\\is-os\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from tensorflow) (2.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in c:\\users\\is-os\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from tensorflow) (4.4.0)\n",
      "Collecting flatbuffers~=1.12\n",
      "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: google-pasta~=0.2 in c:\\users\\is-os\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.2 in c:\\users\\is-os\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: wrapt>=1.11.2 in c:\\users\\is-os\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: six>=1.15.0 in c:\\users\\is-os\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: tensorflow-estimator~=2.6 in c:\\users\\is-os\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from tensorflow) (2.6.0)\n",
      "Collecting absl-py~=0.10\n",
      "  Downloading absl_py-0.15.0-py3-none-any.whl (132 kB)\n",
      "     -------------------------------------- 132.0/132.0 kB 2.6 MB/s eta 0:00:00\n",
      "Collecting tensorflow-estimator~=2.6\n",
      "  Using cached tensorflow_estimator-2.10.0-py2.py3-none-any.whl (438 kB)\n",
      "Collecting libclang>=13.0.0\n",
      "  Using cached libclang-14.0.6-py2.py3-none-win_amd64.whl (14.2 MB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\is-os\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from tensorflow-gpu) (65.5.0)\n",
      "Collecting tensorboard~=2.6\n",
      "  Using cached tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\n",
      "Requirement already satisfied: packaging in c:\\users\\is-os\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from tensorflow-gpu) (22.0)\n",
      "Collecting tensorflow-gpu\n",
      "  Using cached tensorflow_gpu-2.10.0-cp39-cp39-win_amd64.whl (455.9 MB)\n",
      "  Using cached tensorflow_gpu-2.9.3-cp39-cp39-win_amd64.whl (444.1 MB)\n",
      "Collecting tensorboard~=2.6\n",
      "  Downloading tensorboard-2.9.1-py3-none-any.whl (5.8 MB)\n",
      "     ---------------------------------------- 5.8/5.8 MB 1.6 MB/s eta 0:00:00\n",
      "Collecting keras>=2.4.0\n",
      "  Downloading keras-2.9.0-py2.py3-none-any.whl (1.6 MB)\n",
      "     ---------------------------------------- 1.6/1.6 MB 1.5 MB/s eta 0:00:00\n",
      "Collecting tensorflow-gpu\n",
      "  Using cached tensorflow_gpu-2.9.2-cp39-cp39-win_amd64.whl (444.1 MB)\n",
      "  Using cached tensorflow_gpu-2.9.1-cp39-cp39-win_amd64.whl (444.0 MB)\n",
      "  Using cached tensorflow_gpu-2.9.0-cp39-cp39-win_amd64.whl (444.0 MB)\n",
      "  Using cached tensorflow_gpu-2.8.4-cp39-cp39-win_amd64.whl (438.4 MB)\n",
      "Collecting tensorboard~=2.6\n",
      "  Downloading tensorboard-2.8.0-py3-none-any.whl (5.8 MB)\n",
      "     ---------------------------------------- 5.8/5.8 MB 1.4 MB/s eta 0:00:00\n",
      "Collecting tensorflow-estimator~=2.6\n",
      "  Downloading tensorflow_estimator-2.8.0-py2.py3-none-any.whl (462 kB)\n",
      "     -------------------------------------- 462.3/462.3 kB 1.3 MB/s eta 0:00:00\n",
      "Collecting keras>=2.4.0\n",
      "  Downloading keras-2.8.0-py2.py3-none-any.whl (1.4 MB)\n",
      "     ---------------------------------------- 1.4/1.4 MB 1.2 MB/s eta 0:00:00\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.29.0-cp39-cp39-win_amd64.whl (1.5 MB)\n",
      "     ---------------------------------------- 1.5/1.5 MB 1.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\is-os\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Collecting contourpy>=1.0.1\n",
      "  Downloading contourpy-1.0.6-cp39-cp39-win_amd64.whl (161 kB)\n",
      "     -------------------------------------- 161.3/161.3 kB 1.9 MB/s eta 0:00:00\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Using cached kiwisolver-1.4.4-cp39-cp39-win_amd64.whl (55 kB)\n",
      "Collecting pyparsing>=2.2.1\n",
      "  Using cached pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
      "Collecting cycler>=0.10\n",
      "  Using cached cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Using cached fonttools-4.38.0-py3-none-any.whl (965 kB)\n",
      "Collecting scikit-image>=0.16.1\n",
      "  Downloading scikit_image-0.19.3-cp39-cp39-win_amd64.whl (12.1 MB)\n",
      "     ---------------------------------------- 12.1/12.1 MB 1.3 MB/s eta 0:00:00\n",
      "Collecting opencv-python-headless>=4.1.1\n",
      "  Downloading opencv_python_headless-4.7.0.68-cp37-abi3-win_amd64.whl (38.1 MB)\n",
      "     -------------------------------------- 38.1/38.1 MB 379.7 kB/s eta 0:00:00\n",
      "Collecting qudida>=0.0.4\n",
      "  Downloading qudida-0.0.4-py3-none-any.whl (3.5 kB)\n",
      "Requirement already satisfied: scipy in c:\\users\\is-os\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from albumentations) (1.9.3)\n",
      "Collecting PyQt5-Qt5>=5.15.0\n",
      "  Downloading PyQt5_Qt5-5.15.2-py3-none-win_amd64.whl (50.1 MB)\n",
      "     ---------------------------------------- 50.1/50.1 MB 2.3 MB/s eta 0:00:00\n",
      "Collecting PyQt5-sip<13,>=12.11\n",
      "  Downloading PyQt5_sip-12.11.0-cp39-cp39-win_amd64.whl (78 kB)\n",
      "     ---------------------------------------- 78.3/78.3 kB 2.1 MB/s eta 0:00:00\n",
      "Collecting scikit-learn>=0.19.1\n",
      "  Downloading scikit_learn-1.2.0-cp39-cp39-win_amd64.whl (8.3 MB)\n",
      "     ---------------------------------------- 8.3/8.3 MB 2.4 MB/s eta 0:00:00\n",
      "Collecting imageio>=2.4.1\n",
      "  Downloading imageio-2.23.0-py3-none-any.whl (3.4 MB)\n",
      "     ---------------------------------------- 3.4/3.4 MB 1.8 MB/s eta 0:00:00\n",
      "Collecting PyWavelets>=1.1.1\n",
      "  Downloading PyWavelets-1.4.1-cp39-cp39-win_amd64.whl (4.2 MB)\n",
      "     ---------------------------------------- 4.2/4.2 MB 2.4 MB/s eta 0:00:00\n",
      "Collecting tifffile>=2019.7.26\n",
      "  Downloading tifffile-2022.10.10-py3-none-any.whl (210 kB)\n",
      "     -------------------------------------- 210.3/210.3 kB 2.6 MB/s eta 0:00:00\n",
      "Collecting networkx>=2.2\n",
      "  Downloading networkx-3.0-py3-none-any.whl (2.0 MB)\n",
      "     ---------------------------------------- 2.0/2.0 MB 2.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\is-os\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\is-os\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\is-os\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\is-os\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\is-os\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\is-os\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (2.6.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\is-os\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\is-os\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\is-os\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\is-os\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.2.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\is-os\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\is-os\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow) (4.11.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\is-os\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (1.26.13)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\is-os\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\is-os\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\is-os\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2.0.4)\n",
      "Collecting joblib>=1.1.1\n",
      "  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n",
      "     -------------------------------------- 298.0/298.0 kB 1.8 MB/s eta 0:00:00\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\is-os\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from werkzeug>=0.11.15->tensorboard~=2.6->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\is-os\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\is-os\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\is-os\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (3.2.1)\n",
      "Building wheels for collected packages: labelme, clang, imgviz\n",
      "  Building wheel for labelme (setup.py): started\n",
      "  Building wheel for labelme (setup.py): finished with status 'done'\n",
      "  Created wheel for labelme: filename=labelme-5.1.1-py3-none-any.whl size=1466365 sha256=54fdf5e884dff6b57e0af4dfb7cdcaad391b40d74522b13feec434546c77312d\n",
      "  Stored in directory: c:\\users\\is-os\\appdata\\local\\pip\\cache\\wheels\\a6\\e0\\2d\\979211f1da46376a60d8e7a0eefe8830fd34581110a710817f\n",
      "  Building wheel for clang (setup.py): started\n",
      "  Building wheel for clang (setup.py): finished with status 'done'\n",
      "  Created wheel for clang: filename=clang-5.0-py3-none-any.whl size=30686 sha256=4657b49ecefd93a872d40a5e780fe53b93b61f8e9b908b9de4dff3d7200267c6\n",
      "  Stored in directory: c:\\users\\is-os\\appdata\\local\\pip\\cache\\wheels\\10\\e2\\7f\\da1b7d21c67aaea7a1b72230be6051786d1c3a5626334108aa\n",
      "  Building wheel for imgviz (pyproject.toml): started\n",
      "  Building wheel for imgviz (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for imgviz: filename=imgviz-1.6.2-py3-none-any.whl size=7681474 sha256=6933b174422d4183c53b57f479dc491db0c7c7b01873fa9ea1ecc3acac189e87\n",
      "  Stored in directory: c:\\users\\is-os\\appdata\\local\\pip\\cache\\wheels\\3f\\5b\\a3\\5dffe3992c48b99b8bde30d27ddae2c670e0c4c5718aa00a0d\n",
      "Successfully built labelme clang imgviz\n",
      "Installing collected packages: tensorflow-estimator, PyQt5-Qt5, libclang, keras, flatbuffers, clang, tifffile, threadpoolctl, tensorflow-io-gcs-filesystem, qtpy, PyYAML, PyWavelets, PyQt5-sip, pyparsing, Pillow, opencv-python-headless, opencv-python, networkx, natsort, kiwisolver, joblib, fonttools, cycler, contourpy, absl-py, scikit-learn, PyQt5, matplotlib, imageio, scikit-image, qudida, imgviz, tensorboard, labelme, albumentations, tensorflow-gpu\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 2.6.0\n",
      "    Uninstalling tensorflow-estimator-2.6.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.6.0\n",
      "  Attempting uninstall: flatbuffers\n",
      "    Found existing installation: flatbuffers 20210226132247\n",
      "    Uninstalling flatbuffers-20210226132247:\n",
      "      Successfully uninstalled flatbuffers-20210226132247\n",
      "  Attempting uninstall: absl-py\n",
      "    Found existing installation: absl-py 1.3.0\n",
      "    Uninstalling absl-py-1.3.0:\n",
      "      Successfully uninstalled absl-py-1.3.0\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.6.0\n",
      "    Uninstalling tensorboard-2.6.0:\n",
      "      Successfully uninstalled tensorboard-2.6.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'C:\\\\Users\\\\is-os\\\\anaconda3\\\\envs\\\\tf-gpu\\\\Lib\\\\site-packages\\\\tensorflow\\\\lite\\\\experimental\\\\microfrontend\\\\python\\\\ops\\\\_audio_microfrontend_op.so'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install labelme tensorflow tensorflow-gpu opencv-python matplotlib albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2f5eb61-53ff-4f9e-9279-fcebd24effef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import uuid\n",
    "import time\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a9eaec8-fc6b-4246-811d-6329cc96806f",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_path= os.path.join('data','images')\n",
    "n_imgs=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c471a03-8055-4c7b-b8a8-8b8d3880eb10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collecting imgs 0\n",
      "collecting imgs 1\n",
      "collecting imgs 2\n",
      "collecting imgs 3\n",
      "collecting imgs 4\n",
      "collecting imgs 5\n",
      "collecting imgs 6\n",
      "collecting imgs 7\n",
      "collecting imgs 8\n",
      "collecting imgs 9\n",
      "collecting imgs 10\n",
      "collecting imgs 11\n",
      "collecting imgs 12\n",
      "collecting imgs 13\n",
      "collecting imgs 14\n",
      "collecting imgs 15\n",
      "collecting imgs 16\n",
      "collecting imgs 17\n",
      "collecting imgs 18\n",
      "collecting imgs 19\n",
      "collecting imgs 20\n",
      "collecting imgs 21\n",
      "collecting imgs 22\n",
      "collecting imgs 23\n",
      "collecting imgs 24\n",
      "collecting imgs 25\n",
      "collecting imgs 26\n",
      "collecting imgs 27\n",
      "collecting imgs 28\n",
      "collecting imgs 29\n"
     ]
    }
   ],
   "source": [
    "cam=cv2.VideoCapture(0)\n",
    "for imgnum in range(n_imgs):\n",
    "    print('collecting imgs {}'.format(imgnum))\n",
    "    rtrn,frame=cam.read()\n",
    "    imgname=os.path.join(imgs_path,f'{str(uuid.uuid1())}.jpg')\n",
    "    cv2.imwrite(imgname,frame)\n",
    "    cv2.imshow('picturefrm',frame)\n",
    "    time.sleep(0.5)\n",
    "    if cv2.waitKey(0) & 0xFF == ord('q'):\n",
    "        break\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd749fd5-76dd-4fbc-8739-b4404c9c1bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!labelme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02c5ad8e-fed9-498d-a7b1-f95d378dec62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0515ffb-f36a-4e73-b0ba-f92d5e281495",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Physical devices cannot be modified after being initialized",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m gpus \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mlist_physical_devices(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGPU\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m gpu \u001b[38;5;129;01min\u001b[39;00m gpus: \n\u001b[1;32m----> 4\u001b[0m     \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexperimental\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_memory_growth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgpu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\config.py:707\u001b[0m, in \u001b[0;36mset_memory_growth\u001b[1;34m(device, enable)\u001b[0m\n\u001b[0;32m    682\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconfig.experimental.set_memory_growth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    683\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_memory_growth\u001b[39m(device, enable):\n\u001b[0;32m    684\u001b[0m   \u001b[38;5;124;03m\"\"\"Set if memory growth should be enabled for a `PhysicalDevice`.\u001b[39;00m\n\u001b[0;32m    685\u001b[0m \n\u001b[0;32m    686\u001b[0m \u001b[38;5;124;03m  If memory growth is enabled for a `PhysicalDevice`, the runtime initialization\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    705\u001b[0m \u001b[38;5;124;03m    RuntimeError: Runtime is already initialized.\u001b[39;00m\n\u001b[0;32m    706\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 707\u001b[0m   \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_memory_growth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menable\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\context.py:1501\u001b[0m, in \u001b[0;36mContext.set_memory_growth\u001b[1;34m(self, dev, enable)\u001b[0m\n\u001b[0;32m   1498\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m   1500\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_context_handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1501\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1502\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPhysical devices cannot be modified after being initialized\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1504\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_memory_growth_map[dev] \u001b[38;5;241m=\u001b[39m enable\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Physical devices cannot be modified after being initialized"
     ]
    }
   ],
   "source": [
    "#Limit GPU Memory Growth\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus: \n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "674d61df-fed5-4112-a02e-889f810ee5cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da3bcaf3-43e3-4c4f-bb08-4aa56460cf60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\is-os\\AppData\\Local\\Temp\\ipykernel_21220\\337460670.py:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "785d6331-35c2-44e4-814f-153a4caebc93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function tensorflow.python.platform.test.is_built_with_cuda()>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_built_with_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d61815dc-138f-4372-bdeb-28739350ff82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting tensorflow-gpu\n",
      "  Using cached tensorflow_gpu-2.10.1-cp39-cp39-win_amd64.whl (455.9 MB)\n",
      "Collecting keras<2.11,>=2.10.0\n",
      "  Downloading keras-2.10.0-py2.py3-none-any.whl (1.7 MB)\n",
      "     ---------------------------------------- 1.7/1.7 MB 770.7 kB/s eta 0:00:00\n",
      "Collecting keras-preprocessing>=1.1.1\n",
      "  Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\is-os\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (4.4.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\is-os\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (22.12.6)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\is-os\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (1.51.1)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\is-os\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (3.19.6)\n",
      "Collecting tensorboard<2.11,>=2.10\n",
      "  Downloading tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\n",
      "     ---------------------------------------- 5.9/5.9 MB 139.3 kB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging in c:\\users\\is-os\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (22.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\is-os\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (14.0.6)\n",
      "Collecting tensorflow-estimator<2.11,>=2.10.0\n",
      "  Downloading tensorflow_estimator-2.10.0-py2.py3-none-any.whl (438 kB)\n",
      "     ------------------------------------ 438.7/438.7 kB 449.6 kB/s eta 0:00:00\n",
      "Requirement already satisfied: setuptools in c:\\users\\is-os\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (65.5.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\is-os\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (1.3.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\is-os\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\is-os\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\is-os\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (3.7.0)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\is-os\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (1.21.5)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\is-os\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\is-os\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (0.28.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\is-os\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (1.6.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\is-os\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (3.3.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\is-os\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (2.1.1)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\is-os\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (1.16.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\is-os\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-gpu) (0.37.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\is-os\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu) (2.28.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\is-os\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu) (2.0.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\is-os\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu) (3.4.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\is-os\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu) (0.4.6)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\is-os\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu) (2.15.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\is-os\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu) (0.6.1)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'C:\\\\Users\\\\is-os\\\\anaconda3\\\\Lib\\\\site-packages\\\\tensorflow\\\\compiler\\\\tf2tensorrt\\\\_pywrap_py_utils.pyd'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\is-os\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu) (1.8.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\is-os\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow-gpu) (5.2.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\is-os\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow-gpu) (4.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\is-os\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow-gpu) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\is-os\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow-gpu) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\is-os\\anaconda3\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow-gpu) (4.11.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\is-os\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow-gpu) (1.26.13)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\is-os\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow-gpu) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\is-os\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow-gpu) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\is-os\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow-gpu) (2022.12.7)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\is-os\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow-gpu) (3.11.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\is-os\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow-gpu) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\is-os\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow-gpu) (3.2.2)\n",
      "Installing collected packages: keras, tensorflow-estimator, keras-preprocessing, tensorboard, tensorflow-gpu\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: keras 2.11.0\n",
      "    Uninstalling keras-2.11.0:\n",
      "      Successfully uninstalled keras-2.11.0\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 2.11.0\n",
      "    Uninstalling tensorflow-estimator-2.11.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.11.0\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.11.0\n",
      "    Uninstalling tensorboard-2.11.0:\n",
      "      Successfully uninstalled tensorboard-2.11.0\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4130178-e53d-4866-ba8c-36a871adf818",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21220\\337460670.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_gpu_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d07f866b-5cb4-48f8-baec-785e5173e75d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "92fc0241-f297-4ec8-9432-0bedf93837ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = tf.data.Dataset.list_files('data\\\\images\\\\*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eaed77c3-cb1d-46a9-b385-31d08b4dd974",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'data\\\\images\\\\ae93120a-8ea7-11ed-8f4c-9828a63d5a3b.jpg'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb2b12d1-354b-4dff-ac11-8af7a576a132",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'data\\\\images\\\\00214b32-8ea7-11ed-aeb7-9828a63d5a3b.jpg'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3142059f-b1d8-457c-ad75-2d844134460e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadimg (x):\n",
    "    byteimg=tf.io.read_file(x)\n",
    "    img=tf.io.decode_jpeg(byteimg)\n",
    "    return img\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "292407e3-54c6-4263-b478-9d121d07d2ba",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n    C:\\Users\\is-os\\AppData\\Local\\Temp\\ipykernel_21220\\4199762091.py:2 loadimg  *\n        byteimg=tf.io.read_file(x)\n    C:\\Users\\is-os\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\io_ops.py:139 read_file  **\n        return gen_io_ops.read_file(filename, name)\n    C:\\Users\\is-os\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py:559 read_file\n        _, _, _op, _outputs = _op_def_library._apply_op_helper(\n    C:\\Users\\is-os\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:544 _apply_op_helper\n        raise TypeError(\"%s expected type of %s.\" %\n\n    TypeError: Input 'filename' of 'ReadFile' Op has type uint8 that does not match expected type of string.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21220\\952769600.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mimages\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloadimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[1;34m(self, map_func, num_parallel_calls, deterministic)\u001b[0m\n\u001b[0;32m   1859\u001b[0m         warnings.warn(\"The `deterministic` argument has no effect unless the \"\n\u001b[0;32m   1860\u001b[0m                       \"`num_parallel_calls` argument is specified.\")\n\u001b[1;32m-> 1861\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mMapDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreserve_cardinality\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1862\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1863\u001b[0m       return ParallelMapDataset(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality, use_legacy_function)\u001b[0m\n\u001b[0;32m   4979\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_use_inter_op_parallelism\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0muse_inter_op_parallelism\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4980\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_preserve_cardinality\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreserve_cardinality\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4981\u001b[1;33m     self._map_func = StructuredFunctionWrapper(\n\u001b[0m\u001b[0;32m   4982\u001b[0m         \u001b[0mmap_func\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4983\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_transformation_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[0;32m   4216\u001b[0m         \u001b[0mfn_factory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrace_tf_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdefun_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4218\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn_factory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4219\u001b[0m     \u001b[1;31m# There is no graph to add in eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4220\u001b[0m     \u001b[0madd_to_graph\u001b[0m \u001b[1;33m&=\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mget_concrete_function\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3148\u001b[0m          \u001b[1;32mor\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mor\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensorSpec\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3149\u001b[0m     \"\"\"\n\u001b[1;32m-> 3150\u001b[1;33m     graph_function = self._get_concrete_function_garbage_collected(\n\u001b[0m\u001b[0;32m   3151\u001b[0m         *args, **kwargs)\n\u001b[0;32m   3152\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_garbage_collector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3114\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3115\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3116\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3117\u001b[0m       \u001b[0mseen_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3118\u001b[0m       captured = object_identity.ObjectIdentitySet(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3461\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3462\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3463\u001b[1;33m           \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3464\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3465\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3296\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3297\u001b[0m     graph_function = ConcreteFunction(\n\u001b[1;32m-> 3298\u001b[1;33m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m   3299\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3300\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   1005\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1007\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1008\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1009\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m   4193\u001b[0m           attributes=defun_kwargs)\n\u001b[0;32m   4194\u001b[0m       \u001b[1;32mdef\u001b[0m \u001b[0mwrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=missing-docstring\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4195\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwrapper_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4196\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_tensor_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output_structure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4197\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36mwrapper_helper\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m   4123\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0m_should_unpack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4124\u001b[0m         \u001b[0mnested_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4125\u001b[1;33m       \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mautograph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4126\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0m_should_pack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4127\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    693\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    694\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ag_error_metadata'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 695\u001b[1;33m           \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    696\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    697\u001b[0m           \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: in user code:\n\n    C:\\Users\\is-os\\AppData\\Local\\Temp\\ipykernel_21220\\4199762091.py:2 loadimg  *\n        byteimg=tf.io.read_file(x)\n    C:\\Users\\is-os\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\io_ops.py:139 read_file  **\n        return gen_io_ops.read_file(filename, name)\n    C:\\Users\\is-os\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py:559 read_file\n        _, _, _op, _outputs = _op_def_library._apply_op_helper(\n    C:\\Users\\is-os\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:544 _apply_op_helper\n        raise TypeError(\"%s expected type of %s.\" %\n\n    TypeError: Input 'filename' of 'ReadFile' Op has type uint8 that does not match expected type of string.\n"
     ]
    }
   ],
   "source": [
    "images=images.map(loadimg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3873cfa0-2708-40eb-8bc7-f24f5e4d4b93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[120, 106, 103],\n",
       "        [121, 107, 104],\n",
       "        [116, 105, 101],\n",
       "        ...,\n",
       "        [165, 176, 182],\n",
       "        [163, 173, 182],\n",
       "        [162, 175, 183]],\n",
       "\n",
       "       [[118, 107, 105],\n",
       "        [120, 109, 107],\n",
       "        [120, 110, 108],\n",
       "        ...,\n",
       "        [166, 175, 182],\n",
       "        [166, 176, 185],\n",
       "        [165, 178, 186]],\n",
       "\n",
       "       [[113, 104, 105],\n",
       "        [114, 105, 106],\n",
       "        [118, 113, 110],\n",
       "        ...,\n",
       "        [171, 180, 187],\n",
       "        [170, 181, 187],\n",
       "        [169, 180, 186]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[139, 153, 153],\n",
       "        [137, 153, 152],\n",
       "        [136, 152, 149],\n",
       "        ...,\n",
       "        [ 58,  62,  48],\n",
       "        [ 53,  57,  43],\n",
       "        [ 48,  52,  38]],\n",
       "\n",
       "       [[138, 154, 153],\n",
       "        [138, 154, 153],\n",
       "        [137, 153, 150],\n",
       "        ...,\n",
       "        [ 56,  59,  48],\n",
       "        [ 55,  58,  47],\n",
       "        [ 54,  57,  46]],\n",
       "\n",
       "       [[137, 153, 152],\n",
       "        [138, 154, 153],\n",
       "        [137, 156, 152],\n",
       "        ...,\n",
       "        [ 60,  63,  52],\n",
       "        [ 56,  59,  48],\n",
       "        [ 53,  56,  45]]], dtype=uint8)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8b31cb18-bb85-409d-b265-269deea4e37f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.data.ops.dataset_ops.MapDataset"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eb65ee68-8575-4126-9f30-cd9b576372e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_gen = images.batch(4).as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "400ebb6d-73a1-441e-a412-f5ac59b18ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotimg=img_gen.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644edf91-4272-40d0-9953-d02297dcf5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=4, figsize=(20,20))\n",
    "for index, image in enumerate(plotimg):\n",
    "    ax[index].imshow(image) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "65dc0a10-a138-4778-b560-dff17fe1cf3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fldr in ['train','test','val']:\n",
    "    for file in os.listdir(os.path.join('data', fldr, 'images')):\n",
    "        \n",
    "        filename = file.split('.')[0]+'.json'\n",
    "        existing_filepath = os.path.join('data','labels', filename)\n",
    "        if os.path.exists(existing_filepath): \n",
    "            new_filepath = os.path.join('data',fldr,'labels',filename)\n",
    "            os.replace(existing_filepath, new_filepath)     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce1936f5-c8a7-4f21-9e1a-0a737f572c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as alb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb2333da-e81d-40b7-a873-ab6107d412e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "augm = alb.Compose([alb.RandomCrop(width=450, height=450), \n",
    "                         alb.HorizontalFlip(p=0.5), \n",
    "                         alb.RandomBrightnessContrast(p=0.2),\n",
    "                         alb.RandomGamma(p=0.2), \n",
    "                         alb.RGBShift(p=0.2), \n",
    "                         alb.VerticalFlip(p=0.5)], \n",
    "                       bbox_params=alb.BboxParams(format='albumentations', \n",
    "                                                  label_fields=['class_labels']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1d1be9d2-1029-4600-9a6e-fb5af7cdb5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(os.path.join('data','train', 'images','0ebde5c2-8ea7-11ed-a890-9828a63d5a3b.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2cb0709e-eb93-467d-8c04-dc0631a01741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480, 640, 3)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5c97181a-0d14-43ca-b4ab-e2541548d441",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join('data', 'train', 'labels', '0ebde5c2-8ea7-11ed-a890-9828a63d5a3b.json'), 'r') as f:\n",
    "    label = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "89979efc-b943-4781-ae8c-67e65b07f9b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "485.06972019770467"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label['shapes'][0]['points'][0][0]\n",
    "label['shapes'][0]['points'][0][1]\n",
    "label['shapes'][0]['points'][1][0]\n",
    "label['shapes'][0]['points'][1][1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7ef152a2-4cef-4ee1-a70e-ecc0654ce7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinates=[0,0,0,0]\n",
    "coordinates[0]=label['shapes'][0]['points'][0][0]\n",
    "coordinates[1]=label['shapes'][0]['points'][0][1]\n",
    "coordinates[2]=label['shapes'][0]['points'][1][0]\n",
    "coordinates[3]=label['shapes'][0]['points'][1][1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "09a1f605-b21b-4177-a427-e8969e78b646",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[273.38164251207735, 145.31400966183574, 485.06972019770467, 479.0]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a1027af8-fdf2-4c6b-8634-a1bf89b79046",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7383fdd0-8003-4fe8-a3cb-e0a12514ea9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pascal voc\n",
    "coordinates=list(np.divide(coordinates,[640,480,640,480]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7e247a00-4242-4d5e-9717-dcfeaaeb0669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.4271588164251209,\n",
       " 0.30273752012882443,\n",
       " 0.7579214378089135,\n",
       " 0.9979166666666667]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "1909400a-c6cc-4476-a61e-fa8d168e78b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaledimg=augm(image=img,bboxes=[coordinates],class_labels=['my face'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "1c919a17-9a6b-4ada-a31e-e7cef1112878",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5119592055823942, 0.0)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaledimg['bboxes'][0][:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a26933a9-a8b5-48ac-8317-6f93050ec238",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(450, 450, 3)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaledimg['image'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "528c075b-4348-47cd-a2f7-bb14e3ec47f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['my face']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaledimg['class_labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "297561f9-f7da-4dd6-826a-1d30b6648572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 23,  42,  67],\n",
       "        [ 19,  38,  63],\n",
       "        [ 20,  39,  64],\n",
       "        ...,\n",
       "        [146, 144, 150],\n",
       "        [148, 146, 152],\n",
       "        [147, 142, 149]],\n",
       "\n",
       "       [[ 23,  44,  69],\n",
       "        [ 17,  38,  63],\n",
       "        [ 18,  39,  64],\n",
       "        ...,\n",
       "        [153, 148, 155],\n",
       "        [155, 150, 157],\n",
       "        [153, 148, 155]],\n",
       "\n",
       "       [[ 17,  40,  65],\n",
       "        [ 12,  35,  60],\n",
       "        [ 12,  35,  60],\n",
       "        ...,\n",
       "        [159, 154, 161],\n",
       "        [159, 154, 161],\n",
       "        [162, 158, 163]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[143, 158, 176],\n",
       "        [148, 161, 179],\n",
       "        [144, 157, 175],\n",
       "        ...,\n",
       "        [195, 202, 221],\n",
       "        [196, 203, 222],\n",
       "        [195, 202, 221]],\n",
       "\n",
       "       [[134, 151, 170],\n",
       "        [141, 156, 175],\n",
       "        [140, 155, 174],\n",
       "        ...,\n",
       "        [196, 201, 220],\n",
       "        [195, 200, 219],\n",
       "        [194, 199, 218]],\n",
       "\n",
       "       [[131, 148, 167],\n",
       "        [137, 152, 171],\n",
       "        [138, 153, 172],\n",
       "        ...,\n",
       "        [193, 198, 217],\n",
       "        [194, 199, 218],\n",
       "        [194, 199, 218]]], dtype=uint8)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.rectangle(scaledimg['image'],tuple(np.multiply(scaledimg['bboxes'][0][:2], [450,450]).astype(int)),\n",
    "              tuple(np.multiply(scaledimg['bboxes'][0][2:], [450,450]).astype(int)),(0,255,0), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83797a35-22be-4efe-ab47-0f368079f14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(scaledimg['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "c6fc2dee-0019-460d-9580-cb0076a29a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for partition in ['train','test','val']: \n",
    "    for image in os.listdir(os.path.join('data', partition, 'images')):\n",
    "        img = cv2.imread(os.path.join('data', partition, 'images', image))\n",
    "\n",
    "        coords = [0,0,0.00001,0.00001]\n",
    "        label_path = os.path.join('data', partition, 'labels', f'{image.split(\".\")[0]}.json')\n",
    "        if os.path.exists(label_path):\n",
    "            with open(label_path, 'r') as f:\n",
    "                label = json.load(f)\n",
    "\n",
    "            coords[0] = label['shapes'][0]['points'][0][0]\n",
    "            coords[1] = label['shapes'][0]['points'][0][1]\n",
    "            coords[2] = label['shapes'][0]['points'][1][0]\n",
    "            coords[3] = label['shapes'][0]['points'][1][1]\n",
    "            coords = list(np.divide(coords, [640,480,640,480]))\n",
    "\n",
    "        try: \n",
    "            for x in range(60):\n",
    "                scaledimg = augm(image=img, bboxes=[coords], class_labels=['my face'])\n",
    "                cv2.imwrite(os.path.join('augmenteddata', partition, 'images', f'{image.split(\".\")[0]}.{x}.jpg'), scaledimg['image'])\n",
    "\n",
    "                annotation = {}\n",
    "                annotation['image'] = image\n",
    "\n",
    "                if os.path.exists(label_path):\n",
    "                    if len(scaledimg['bboxes']) == 0: \n",
    "                        annotation['bbox'] = [0,0,0,0]\n",
    "                        annotation['class'] = 0 \n",
    "                    else: \n",
    "                        annotation['bbox'] = scaledimg['bboxes'][0]\n",
    "                        annotation['class'] = 1\n",
    "                else: \n",
    "                    annotation['bbox'] = [0,0,0,0]\n",
    "                    annotation['class'] = 0 \n",
    "\n",
    "\n",
    "                with open(os.path.join('augmenteddata', partition, 'labels', f'{image.split(\".\")[0]}.{x}.json'), 'w') as f:\n",
    "                    json.dump(annotation, f)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "137d650d-7834-4463-a21b-135f72d804e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Augmented Images to Tensorflow Dataset\n",
    "train_images = tf.data.Dataset.list_files('augmenteddata\\\\train\\\\images\\\\*.jpg', shuffle=False)\n",
    "train_images = train_images.map(loadimg)\n",
    "train_images = train_images.map(lambda x: tf.image.resize(x, (120,120)))\n",
    "train_images = train_images.map(lambda x: x/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "703bdc5a-fded-44ad-9c77-8d53a33ac210",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = tf.data.Dataset.list_files('augmenteddata\\\\test\\\\images\\\\*.jpg', shuffle=False)\n",
    "test_images = test_images.map(loadimg)\n",
    "test_images = test_images.map(lambda x: tf.image.resize(x, (120,120)))\n",
    "test_images = test_images.map(lambda x: x/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c0e7db65-c34f-4bc8-8de9-172fe25a2311",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_images = tf.data.Dataset.list_files('augmenteddata\\\\val\\\\images\\\\*.jpg', shuffle=False)\n",
    "val_images = val_images.map(loadimg)\n",
    "val_images = val_images.map(lambda x: tf.image.resize(x, (120,120)))\n",
    "val_images = val_images.map(lambda x: x/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3f262a55-e9f3-40cc-befd-db4268aceabe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.20441176, 0.21911764, 0.2372549 ],\n",
       "        [0.70594364, 0.72028184, 0.73860294],\n",
       "        [0.7757966 , 0.7875613 , 0.80716914],\n",
       "        ...,\n",
       "        [0.18155637, 0.15067402, 0.02781863],\n",
       "        [0.16507353, 0.14497548, 0.02634804],\n",
       "        [0.17242648, 0.15980393, 0.06433824]],\n",
       "\n",
       "       [[0.15245098, 0.17996323, 0.19270833],\n",
       "        [0.39362746, 0.4122549 , 0.42843136],\n",
       "        [0.7495098 , 0.7617647 , 0.78039217],\n",
       "        ...,\n",
       "        [0.16599265, 0.1463848 , 0.0278799 ],\n",
       "        [0.20245098, 0.18198529, 0.06819853],\n",
       "        [0.17077206, 0.14705883, 0.05      ]],\n",
       "\n",
       "       [[0.18651961, 0.21789216, 0.22573529],\n",
       "        [0.22052696, 0.2396446 , 0.25140932],\n",
       "        [0.5448529 , 0.5487745 , 0.5644608 ],\n",
       "        ...,\n",
       "        [0.17340687, 0.15379901, 0.03915441],\n",
       "        [0.18370098, 0.15723039, 0.04644608],\n",
       "        [0.17536765, 0.14491421, 0.0504902 ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.73762256, 0.7357843 , 0.7050858 ],\n",
       "        [0.74172795, 0.72996324, 0.6946691 ],\n",
       "        [0.736826  , 0.736826  , 0.70545346],\n",
       "        ...,\n",
       "        [0.5951593 , 0.579473  , 0.5324142 ],\n",
       "        [0.5926471 , 0.5769608 , 0.53333336],\n",
       "        [0.5857843 , 0.57009804, 0.5235294 ]],\n",
       "\n",
       "       [[0.7484069 , 0.73125   , 0.69644606],\n",
       "        [0.74019605, 0.725     , 0.69056374],\n",
       "        [0.7357843 , 0.7357843 , 0.70441175],\n",
       "        ...,\n",
       "        [0.5917279 , 0.57604164, 0.5289828 ],\n",
       "        [0.5955882 , 0.57990193, 0.5427696 ],\n",
       "        [0.5926471 , 0.5769608 , 0.5416667 ]],\n",
       "\n",
       "       [[0.75104165, 0.734375  , 0.70643383],\n",
       "        [0.75214463, 0.7354779 , 0.7079044 ],\n",
       "        [0.7498162 , 0.74191177, 0.71317405],\n",
       "        ...,\n",
       "        [0.6039216 , 0.5882353 , 0.5411765 ],\n",
       "        [0.59001225, 0.56789213, 0.5337623 ],\n",
       "        [0.58982843, 0.5667892 , 0.5339461 ]]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "263b41f4-5896-4bea-a4a6-e87f523c3ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_labels(label_path):\n",
    "    with open(label_path.numpy(), 'r', encoding = \"utf-8\") as f:\n",
    "        label = json.load(f)\n",
    "        \n",
    "    return [label['class']], label['bbox']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "24a38e24-a1fc-46c8-a838-c4b5111a3752",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = tf.data.Dataset.list_files('augmenteddata\\\\train\\\\labels\\\\*.json', shuffle=False)\n",
    "train_labels = train_labels.map(lambda x: tf.py_function(load_labels, [x], [tf.uint8, tf.float16]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b62a39ee-375b-4dd0-b668-d9ed8f0ed46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = tf.data.Dataset.list_files('augmenteddata\\\\test\\\\labels\\\\*.json', shuffle=False)\n",
    "test_labels = test_labels.map(lambda x: tf.py_function(load_labels, [x], [tf.uint8, tf.float16]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9890d730-4a61-41ec-a1f0-59e5a9106db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_labels = tf.data.Dataset.list_files('augmenteddata\\\\val\\\\labels\\\\*.json', shuffle=False)\n",
    "val_labels = val_labels.map(lambda x: tf.py_function(load_labels, [x], [tf.uint8, tf.float16]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0e12d680-f5e7-48e2-8b83-8ed184fc4bbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3780, 3780, 840, 840, 780, 780)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_images), len(train_labels), len(test_images), len(test_labels), len(val_images), len(val_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "de54bf26-1f15-48c7-bf17-2ed326c35635",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = tf.data.Dataset.zip((train_images, train_labels))\n",
    "train = train.shuffle(5000)\n",
    "train = train.batch(8)\n",
    "train = train.prefetch(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6ec1e7c6-58df-4798-a29e-fe5eedc0461e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = tf.data.Dataset.zip((test_images, test_labels))\n",
    "test = test.shuffle(1300)\n",
    "test = test.batch(8)\n",
    "test = test.prefetch(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fda8e6cd-f007-486d-8d25-febdc482cd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "val = tf.data.Dataset.zip((val_images, val_labels))\n",
    "val = val.shuffle(1000)\n",
    "val = val.batch(8)\n",
    "val = val.prefetch(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cbee59d7-b47b-4256-9bb4-bc9f9891965e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1]], dtype=uint8),\n",
       " array([[0.3638 , 0.2256 , 0.843  , 0.9634 ],\n",
       "        [0.3044 , 0.02696, 0.821  , 0.7817 ],\n",
       "        [0.08936, 0.3018 , 0.5874 , 1.     ],\n",
       "        [0.     , 0.     , 0.2974 , 0.6777 ],\n",
       "        [0.1517 , 0.2059 , 0.597  , 0.8853 ],\n",
       "        [0.2019 , 0.     , 0.8716 , 0.662  ],\n",
       "        [0.472  , 0.351  , 0.8994 , 0.9395 ],\n",
       "        [0.1305 , 0.0869 , 0.4375 , 0.516  ]], dtype=float16))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.as_numpy_iterator().next()[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c62331b3-d93c-4401-8489-690cce1974a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_samples = train.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4745141c-331b-447a-a8b3-ea40b7ebd4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = data_samples.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac41a8a9-f10b-4298-bc03-ce97eb63393f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=4, figsize=(20,20))\n",
    "for idx in range(4): \n",
    "    sample_image = result[0][idx]\n",
    "    sample_coords = result[1][1][idx]\n",
    "    \n",
    "    cv2.rectangle(sample_image, \n",
    "                  tuple(np.multiply(sample_coords[:2], [120,120]).astype(int)),\n",
    "                  tuple(np.multiply(sample_coords[2:], [120,120]).astype(int)), \n",
    "                        (255,0,0), 2)\n",
    "\n",
    "    ax[idx].imshow(sample_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d57095c0-fcfe-47cc-bf61-7dc900c963cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52f7a90f-5249-4e49-a8cf-7cf28692b278",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Conv2D, Dense, GlobalMaxPooling2D\n",
    "from tensorflow.keras.applications import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba7da18d-ad9c-4212-a7b2-4bad6f6abf16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 22s 0us/step\n"
     ]
    }
   ],
   "source": [
    "vgg = VGG16(include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3db93ac1-73a1-4863-bdc7-8af73577b54c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, None, None, 3)]   0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "336d3b93-1ad3-43a7-968d-392cfcb27d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(): \n",
    "    input_layer = Input(shape=(120,120,3))\n",
    "    \n",
    "    vgg = VGG16(include_top=False)(input_layer)\n",
    "\n",
    "    # Classification Model  \n",
    "    f1 = GlobalMaxPooling2D()(vgg)\n",
    "    class1 = Dense(2048, activation='relu')(f1)\n",
    "    class2 = Dense(1, activation='sigmoid')(class1)\n",
    "    \n",
    "    # Bounding box model\n",
    "    f2 = GlobalMaxPooling2D()(vgg)\n",
    "    regress1 = Dense(2048, activation='relu')(f2)\n",
    "    regress2 = Dense(4, activation='sigmoid')(regress1)\n",
    "    \n",
    "    facetracker = Model(inputs=input_layer, outputs=[class2, regress2])\n",
    "    return facetracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b1f64e15-9509-4fd0-a506-789bd27a5592",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1]], dtype=uint8),\n",
       " array([[0.4265  , 0.009224, 0.8076  , 0.545   ],\n",
       "        [0.3704  , 0.2455  , 0.739   , 0.5825  ],\n",
       "        [0.3066  , 0.368   , 0.7866  , 0.996   ],\n",
       "        [0.261   , 0.342   , 0.688   , 0.9307  ],\n",
       "        [0.846   , 0.      , 1.      , 0.628   ],\n",
       "        [0.2344  , 0.657   , 0.521   , 1.      ],\n",
       "        [0.3728  , 0.4543  , 0.885   , 1.      ],\n",
       "        [0.229   , 0.936   , 0.756   , 1.      ]], dtype=float16))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.as_numpy_iterator().next()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5f396087-78b2-4f61-ab23-72577a440ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "facetracker = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "aa278ae0-e607-4f4f-beb8-34cc90590838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 120, 120, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vgg16 (Functional)              (None, None, None, 5 14714688    input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d (GlobalMax (None, 512)          0           vgg16[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d_1 (GlobalM (None, 512)          0           vgg16[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 2048)         1050624     global_max_pooling2d[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 2048)         1050624     global_max_pooling2d_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            2049        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 4)            8196        dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 16,826,181\n",
      "Trainable params: 16,826,181\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "facetracker.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d3fbc8f1-9518-488a-9ad4-3ec2daa8b148",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = train.as_numpy_iterator().next()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "aaf12229-bd9a-4bff-a637-f4a02d2dc142",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 120, 120, 3)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1e8869c2-2efe-4c59-a385-7c797552e8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes, coords = facetracker.predict(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4fee7d87-073d-4ca8-a689-13a95c90a6fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.42243853],\n",
       "        [0.5236535 ],\n",
       "        [0.51154715],\n",
       "        [0.35114047],\n",
       "        [0.34304678],\n",
       "        [0.4234679 ],\n",
       "        [0.43059266],\n",
       "        [0.43777856]], dtype=float32),\n",
       " array([[0.40223572, 0.47771552, 0.29744253, 0.30058035],\n",
       "        [0.3400945 , 0.52826947, 0.2844856 , 0.20036569],\n",
       "        [0.3640592 , 0.51705766, 0.29359934, 0.26508322],\n",
       "        [0.28196457, 0.5752365 , 0.31496382, 0.16609141],\n",
       "        [0.24076569, 0.5775169 , 0.30741632, 0.22885868],\n",
       "        [0.3488223 , 0.5458324 , 0.23812975, 0.1619801 ],\n",
       "        [0.29621094, 0.5733281 , 0.34374413, 0.2281689 ],\n",
       "        [0.36372262, 0.49054432, 0.31418535, 0.19771087]], dtype=float32))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes, coords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4152c19f-59a0-4536-ba62-43730c02e030",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "473"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "54134503-1f9d-404c-8ff2-b1b60b58120d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Optimizer and LR\n",
    "batches_per_epoch = len(train)\n",
    "lr_decay = (1./0.75 -1)/batches_per_epoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d65d2fe9-a963-4116-8157-7dac464370f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(learning_rate=0.0001, decay=lr_decay)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ad095d37-9ba0-4551-8666-c74bc68d59a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def localization_loss(y_true, yhat):            \n",
    "    delta_coord = tf.reduce_sum(tf.square(y_true[:,:2] - yhat[:,:2]))\n",
    "                  \n",
    "    h_true = y_true[:,3] - y_true[:,1] \n",
    "    w_true = y_true[:,2] - y_true[:,0] \n",
    "\n",
    "    h_pred = yhat[:,3] - yhat[:,1] \n",
    "    w_pred = yhat[:,2] - yhat[:,0] \n",
    "    \n",
    "    delta_size = tf.reduce_sum(tf.square(w_true - w_pred) + tf.square(h_true-h_pred))\n",
    "    \n",
    "    return delta_coord + delta_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "174f7b88-be2e-4c03-92b3-682964937b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "classloss = tf.keras.losses.BinaryCrossentropy()\n",
    "regressloss = localization_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3d6b231b-de39-491d-af3c-0d014c5b0dc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=11.428514>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test loss metriccs\n",
    "\n",
    "localization_loss(y[1], coords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "29483f2f-27b7-49d8-9ee4-e2d193d70f15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.8529149>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classloss(y[0], classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1f6fa1a5-e1bb-47bf-ad58-43756c10056d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=11.428514>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressloss(y[1], coords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2abf40c8-b9dc-4b6c-9cab-227f5732e5ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0007047216349541929"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b88c08bb-436d-4f32-baa7-7bc44d893268",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train Neural Network\n",
    "class FaceTracker(Model): \n",
    "    def __init__(self, eyetracker,  **kwargs): \n",
    "        super().__init__(**kwargs)\n",
    "        self.model = eyetracker\n",
    "\n",
    "    def compile(self, opt, classloss, localizationloss, **kwargs):\n",
    "        super().compile(**kwargs)\n",
    "        self.closs = classloss\n",
    "        self.lloss = localizationloss\n",
    "        self.opt = opt\n",
    "    \n",
    "    def train_step(self, batch, **kwargs): \n",
    "        \n",
    "        X, y = batch\n",
    "        \n",
    "        with tf.GradientTape() as tape: \n",
    "            classes, coords = self.model(X, training=True)\n",
    "            \n",
    "            batch_classloss = self.closs(y[0], classes)\n",
    "            batch_localizationloss = self.lloss(tf.cast(y[1], tf.float32), coords)\n",
    "            \n",
    "            total_loss = batch_localizationloss+0.5*batch_classloss\n",
    "            \n",
    "            grad = tape.gradient(total_loss, self.model.trainable_variables)\n",
    "        \n",
    "        opt.apply_gradients(zip(grad, self.model.trainable_variables))\n",
    "        \n",
    "        return {\"total_loss\":total_loss, \"class_loss\":batch_classloss, \"regress_loss\":batch_localizationloss}\n",
    "    \n",
    "    def test_step(self, batch, **kwargs): \n",
    "        X, y = batch\n",
    "        \n",
    "        classes, coords = self.model(X, training=False)\n",
    "        \n",
    "        batch_classloss = self.closs(y[0], classes)\n",
    "        batch_localizationloss = self.lloss(tf.cast(y[1], tf.float32), coords)\n",
    "        total_loss = batch_localizationloss+0.5*batch_classloss\n",
    "        \n",
    "        return {\"total_loss\":total_loss, \"class_loss\":batch_classloss, \"regress_loss\":batch_localizationloss}\n",
    "        \n",
    "    def call(self, X, **kwargs): \n",
    "        return self.model(X, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0393546a-9fca-414c-a6b8-93a2be8a259e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FaceTracker(facetracker)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d3b10ce2-1bdc-4178-97fa-69388b4ee84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(opt, classloss, regressloss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ee03573a-2c53-46f3-aa55-b35c05e3fbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "logdir='logs'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "897aa956-7943-4ebd-b995-3841508b2754",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a4c72a72-4150-4c1c-b2d9-cef07de36445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "473/473 [==============================] - 118s 208ms/step - total_loss: 0.2860 - class_loss: 0.0432 - regress_loss: 0.2644 - val_total_loss: 0.0137 - val_class_loss: 9.7271e-05 - val_regress_loss: 0.0137\n",
      "Epoch 2/10\n",
      "473/473 [==============================] - 104s 205ms/step - total_loss: 0.0806 - class_loss: 0.0132 - regress_loss: 0.0740 - val_total_loss: 0.0124 - val_class_loss: 4.9175e-04 - val_regress_loss: 0.0122\n",
      "Epoch 3/10\n",
      "473/473 [==============================] - 107s 209ms/step - total_loss: 0.0292 - class_loss: 0.0027 - regress_loss: 0.0279 - val_total_loss: 0.0175 - val_class_loss: 2.0266e-05 - val_regress_loss: 0.0175\n",
      "Epoch 4/10\n",
      "473/473 [==============================] - 114s 222ms/step - total_loss: 0.0322 - class_loss: 0.0046 - regress_loss: 0.0299 - val_total_loss: 0.0222 - val_class_loss: 0.0080 - val_regress_loss: 0.0182\n",
      "Epoch 5/10\n",
      "473/473 [==============================] - 125s 231ms/step - total_loss: 0.0098 - class_loss: 1.8883e-04 - regress_loss: 0.0097 - val_total_loss: 0.0255 - val_class_loss: 1.3845e-04 - val_regress_loss: 0.0254\n",
      "Epoch 6/10\n",
      "473/473 [==============================] - 129s 237ms/step - total_loss: 0.0268 - class_loss: 0.0055 - regress_loss: 0.0240 - val_total_loss: 0.0098 - val_class_loss: 8.1097e-05 - val_regress_loss: 0.0098\n",
      "Epoch 7/10\n",
      "473/473 [==============================] - 127s 234ms/step - total_loss: 0.0136 - class_loss: 0.0032 - regress_loss: 0.0120 - val_total_loss: 0.0055 - val_class_loss: 1.9491e-05 - val_regress_loss: 0.0055\n",
      "Epoch 8/10\n",
      "473/473 [==============================] - 123s 231ms/step - total_loss: 0.0084 - class_loss: 0.0017 - regress_loss: 0.0076 - val_total_loss: 0.0038 - val_class_loss: 4.9472e-06 - val_regress_loss: 0.0038\n",
      "Epoch 9/10\n",
      "473/473 [==============================] - 128s 242ms/step - total_loss: 0.0079 - class_loss: 9.1894e-04 - regress_loss: 0.0075 - val_total_loss: 2.2647 - val_class_loss: 2.2192 - val_regress_loss: 1.1551\n",
      "Epoch 10/10\n",
      "473/473 [==============================] - 139s 260ms/step - total_loss: 0.0121 - class_loss: 0.0012 - regress_loss: 0.0116 - val_total_loss: 0.0070 - val_class_loss: 4.1188e-05 - val_regress_loss: 0.0070\n"
     ]
    }
   ],
   "source": [
    "#traain\n",
    "hist = model.fit(train, epochs=10, validation_data=val, callbacks=[tensorboard_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e04bdcf5-353d-4dcd-b095-b9463a09e7f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'total_loss': [0.045017022639513016,\n",
       "  0.07236533612012863,\n",
       "  0.014868070371448994,\n",
       "  0.0036369068548083305,\n",
       "  0.015382085926830769,\n",
       "  0.0036335806362330914,\n",
       "  0.003945093136280775,\n",
       "  0.002674845978617668,\n",
       "  0.002374919131398201,\n",
       "  0.003945939242839813],\n",
       " 'class_loss': [0.012128889560699463,\n",
       "  0.00043221411760896444,\n",
       "  0.00038213899824768305,\n",
       "  2.984821912832558e-05,\n",
       "  0.0001730743097141385,\n",
       "  8.553358384233434e-06,\n",
       "  0.0007136634667403996,\n",
       "  9.685811164672486e-06,\n",
       "  1.2457543562049977e-05,\n",
       "  1.2427835827111267e-05],\n",
       " 'regress_loss': [0.038952577859163284,\n",
       "  0.07214923202991486,\n",
       "  0.014677001163363457,\n",
       "  0.003621982643380761,\n",
       "  0.015295548364520073,\n",
       "  0.003629304002970457,\n",
       "  0.003588261315599084,\n",
       "  0.0026700031012296677,\n",
       "  0.0023686904460191727,\n",
       "  0.003939725458621979],\n",
       " 'val_total_loss': [0.013716837391257286,\n",
       "  0.01242009922862053,\n",
       "  0.017501819878816605,\n",
       "  0.02224571630358696,\n",
       "  0.0255100317299366,\n",
       "  0.009848962537944317,\n",
       "  0.0055332547053694725,\n",
       "  0.00380179681815207,\n",
       "  2.2646713256835938,\n",
       "  0.007047864142805338],\n",
       " 'val_class_loss': [9.727128053782508e-05,\n",
       "  0.0004917504265904427,\n",
       "  2.0266148567316122e-05,\n",
       "  0.008024969138205051,\n",
       "  0.00013845096691511571,\n",
       "  8.109731425065547e-05,\n",
       "  1.9491033526719548e-05,\n",
       "  4.947209163219668e-06,\n",
       "  2.219195604324341,\n",
       "  4.11880791943986e-05],\n",
       " 'val_regress_loss': [0.013668201863765717,\n",
       "  0.01217422354966402,\n",
       "  0.017491687089204788,\n",
       "  0.01823323220014572,\n",
       "  0.02544080652296543,\n",
       "  0.009808413684368134,\n",
       "  0.005523509345948696,\n",
       "  0.0037993232253938913,\n",
       "  1.155073642730713,\n",
       "  0.007027270272374153]}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d14a9ef7-e56b-459d-b2ba-b998b679eb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make Predictions on Test Set\n",
    "test_data = test.as_numpy_iterator()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5665256a-092e-4637-9c16-be859a1a02cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample = test_data.next()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "623f3b71-04fc-4a34-a2a2-f98792f7fedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = facetracker.predict(test_sample[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfbbe84-cf71-490c-892e-672caf9ac24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=4, figsize=(20,20))\n",
    "for idx in range(4): \n",
    "    sample_image = test_sample[0][idx]\n",
    "    sample_coords = yhat[1][idx]\n",
    "    \n",
    "    if yhat[0][idx] > 0.9:\n",
    "        cv2.rectangle(sample_image, \n",
    "                      tuple(np.multiply(sample_coords[:2], [120,120]).astype(int)),\n",
    "                      tuple(np.multiply(sample_coords[2:], [120,120]).astype(int)), \n",
    "                            (255,0,0), 2)\n",
    "    \n",
    "    ax[idx].imshow(sample_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7a039525-8c82-49fe-bff4-7e28c8c3a0ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "#saving\n",
    "from tensorflow.keras.models import load_model\n",
    "facetracker.save('facetracker.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b2e392ef-2300-45be-a8c9-7fd6aa9cb0ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "facetracker.save('facetracker.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "38997aa9-3ced-435b-89bb-c7fb720175c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "facetracker = load_model('facetracker.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "84ec02d4-82ac-48a1-9fd8-bf7f937317a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#real time detection\n",
    "cam = cv2.VideoCapture(0)\n",
    "while cam.isOpened():\n",
    "    _ , frame = cam.read()\n",
    "    frame = frame[50:500, 50:500,:]\n",
    "    \n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    resized = tf.image.resize(rgb, (120,120))\n",
    "    \n",
    "    yhat = facetracker.predict(np.expand_dims(resized/255,0))\n",
    "    sample_coords = yhat[1][0]\n",
    "    \n",
    "    if yhat[0] > 0.5: \n",
    "        # Controls the main rectangle\n",
    "        cv2.rectangle(frame, \n",
    "                      tuple(np.multiply(sample_coords[:2], [450,450]).astype(int)),\n",
    "                      tuple(np.multiply(sample_coords[2:], [450,450]).astype(int)), \n",
    "                            (255,0,0), 2)\n",
    "        # Controls the label rectangle\n",
    "        cv2.rectangle(frame, \n",
    "                      tuple(np.add(np.multiply(sample_coords[:2], [450,450]).astype(int), \n",
    "                                    [0,-30])),\n",
    "                      tuple(np.add(np.multiply(sample_coords[:2], [450,450]).astype(int),\n",
    "                                    [80,0])), \n",
    "                            (255,0,0), -1)\n",
    "        \n",
    "        # Controls the text rendered\n",
    "        cv2.putText(frame, 'my face', tuple(np.add(np.multiply(sample_coords[:2], [450,450]).astype(int),\n",
    "                                               [0,-5])),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2, cv2.LINE_AA)\n",
    "    \n",
    "    cv2.imshow('EyeTrack', frame)\n",
    "    \n",
    "    if cv2.waitKey(0) & 0xFF == ord('q'):\n",
    "        break\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d672d0f-a3f9-4fd4-bf0f-40ba9ef086c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# Open the image file\n",
    "realimage = Image.open('Capture.PNG')\n",
    "\n",
    "image_array = np.array(realimage)\n",
    "\n",
    "plt.imshow(image_array)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9690a716-d7b6-4302-af0c-7aa3451bb811",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c7d95e-722e-41f9-bac2-9bfdb65bb54e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
